{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 토픽 모델링이란?\n",
    "- 단어들은 각각의 토픽을 가지고 있고 문장은 단어들을 가지고 있으며, 문서는 그러한 문장들을 가지고 있다.\n",
    "- 이에 따라, 단어들의 토픽들을 알게 되면, 해당 문서에는 토픽들의 분포가 형성될 것이며, 크게는 해당 문서의 토픽을 알 수 있게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20 Newgoups 데이터세트로 토픽 모델링하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stopwords는 불필요한 단어, 즉 조사나 관사들을 없애는 툴이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read_json 메소드로 웹에 있는 json 파일을 가지고 온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.autos' 'comp.sys.mac.hardware' 'rec.motorcycles' 'misc.forsale'\n",
      " 'comp.os.ms-windows.misc' 'alt.atheism' 'comp.graphics'\n",
      " 'rec.sport.baseball' 'rec.sport.hockey' 'sci.electronics' 'sci.space'\n",
      " 'talk.politics.misc' 'sci.med' 'talk.politics.mideast'\n",
      " 'soc.religion.christian' 'comp.windows.x' 'comp.sys.ibm.pc.hardware'\n",
      " 'talk.politics.guns' 'talk.religion.misc' 'sci.crypt']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>target</th>\n",
       "      <th>target_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\nS...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>From: irwin@cmptrc.lonestar.org (Irwin Arnstei...</td>\n",
       "      <td>8</td>\n",
       "      <td>rec.motorcycles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>From: tchen@magnus.acs.ohio-state.edu (Tsung-K...</td>\n",
       "      <td>6</td>\n",
       "      <td>misc.forsale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...</td>\n",
       "      <td>2</td>\n",
       "      <td>comp.os.ms-windows.misc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                content  target  \\\n",
       "0     From: lerxst@wam.umd.edu (where's my thing)\\nS...       7   \n",
       "1     From: guykuo@carson.u.washington.edu (Guy Kuo)...       4   \n",
       "10    From: irwin@cmptrc.lonestar.org (Irwin Arnstei...       8   \n",
       "100   From: tchen@magnus.acs.ohio-state.edu (Tsung-K...       6   \n",
       "1000  From: dabl2@nlm.nih.gov (Don A.B. Lindbergh)\\n...       2   \n",
       "\n",
       "                 target_names  \n",
       "0                   rec.autos  \n",
       "1       comp.sys.mac.hardware  \n",
       "10            rec.motorcycles  \n",
       "100              misc.forsale  \n",
       "1000  comp.os.ms-windows.misc  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import Dataset\n",
    "df = pd.read_json('https://raw.githubusercontent.com/selva86/datasets/master/newsgroups.json')\n",
    "print(df.target_names.unique())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['From: (wheres my thing) Subject: WHAT car is this!? Nntp-Posting-Host: '\n",
      " 'rac3.wam.umd.edu Organization: University of Maryland, College Park Lines: '\n",
      " '15 I was wondering if anyone out there could enlighten me on this car I saw '\n",
      " 'the other day. It was a 2-door sports car, looked to be from the late 60s/ '\n",
      " 'early 70s. It was called a Bricklin. The doors were really small. In '\n",
      " 'addition, the front bumper was separate from the rest of the body. This is '\n",
      " 'all I know. If anyone can tellme a model name, engine specs, years of '\n",
      " 'production, where this car is made, history, or whatever info you have on '\n",
      " 'this funky looking car, please e-mail. Thanks, - IL ---- brought to you by '\n",
      " 'your neighborhood Lerxst ---- ']\n"
     ]
    }
   ],
   "source": [
    "# Convert to list\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "# Remove Emails\n",
    "data = [re.sub('\\S*@\\S*\\s?', '', sent) for sent in data]\n",
    "\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 정규식 표현을 통해서 문장 내에 이메일과 기타 특수 문자들을 없애주었지만, 여전히 난잡해보인다.\n",
    "- LDA 알고리즘을 사용하기 위해서는, 문장들을 단어들의 묶음으로 변환시켜주는 과정이 필요하다.\n",
    "- 이러한 과정을 Tokenization 이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tokenization process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  \n",
    "        # deacc=True removes punctuations\n",
    "        # 구두점(말끝에 찍는 쉼표나 점들을 의미) 을 없애주는 것이다.\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram , Trigram 모델 만들기\n",
    "- Bigram : 문서에서 함께 자주 등장하는 2개의 단어\n",
    "- Trigram : 문서에서 함께 자주 등장하는 3개의 단어\n",
    "- ‘front_bumper’, ‘oil_leak’, ‘maryland_college_park’ etc.\n",
    "- Phrases : 모델을 빌드한다.\n",
    "- min_count , threshold : Pharases 의 중요한 두 개의 파라미터\n",
    "    - min_count (float, optional) : Ignore all words and bigrams with total collected count lower than this value.\n",
    "    - threshold (float, optional) : Represent a score threshold for forming the phrases (higher means fewer phrases). A phrase of words a followed by b is accepted if the score of the phrase is greater than threshold. Heavily depends on concrete scoring-function, see the scoring parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hskimim/anaconda3/lib/python3.6/site-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
      "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp_posting_host', 'rac_wam_umd_edu', 'organization', 'university', 'of', 'maryland_college_park', 'lines', 'was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to', 'be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front_bumper', 'was', 'separate', 'from', 'the', 'rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is', 'made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['where', 's', 'thing', 'car', 'nntp_post', 'host', 'rac_wam', 'umd', 'organization', 'university', 'maryland_college', 'park', 'line', 'wonder', 'anyone', 'could', 'enlighten', 'car', 'see', 'day', 'door', 'sport', 'car', 'look', 'late', 'early', 'call', 'bricklin', 'door', 'really', 'small', 'addition', 'front_bumper', 'separate', 'rest', 'body', 'know', 'anyone', 'tellme', 'model', 'name', 'engine', 'spec', 'year', 'production', 'car', 'make', 'history', 'whatev', 'info', 'funky', 'look', 'car', 'mail', 'thank', 'bring', 'neighborhood', 'lerxst']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LDA 모델에 들어가야 하는 두 가지 입력변수는 딕셔너리와(id2word) 코퍼스(corpus)이다.\n",
    "- gensim 은 문서 내에 있는 단어별로 유니크한 아이디를 할당해준다.\n",
    "- 아래의 각각의 엘리먼트 튜플당 의미하는 것은 [word_id,word_frequency] 이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 1), (5, 1), (6, 5), (7, 1), (8, 1), (9, 2), (10, 1), (11, 1), (12, 1), (13, 1), (14, 1), (15, 1), (16, 1), (17, 1), (18, 1), (19, 1), (20, 1), (21, 1), (22, 2), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 1), (41, 1), (42, 1), (43, 1), (44, 1), (45, 1), (46, 1), (47, 1), (48, 1), (49, 1), (50, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "만약 해당 id에 속한 단어를 보고싶으면"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'addition'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 표는 컴퓨터가 읽기 쉽게끔 만들어준 것이고, Counter 객체처럼 사람이 읽기 쉽게 만든 것은 아래와 같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('addition', 1),\n",
       "  ('anyone', 2),\n",
       "  ('body', 1),\n",
       "  ('bricklin', 1),\n",
       "  ('bring', 1),\n",
       "  ('call', 1),\n",
       "  ('car', 5),\n",
       "  ('could', 1),\n",
       "  ('day', 1),\n",
       "  ('door', 2),\n",
       "  ('early', 1),\n",
       "  ('engine', 1),\n",
       "  ('enlighten', 1),\n",
       "  ('front_bumper', 1),\n",
       "  ('funky', 1),\n",
       "  ('history', 1),\n",
       "  ('host', 1),\n",
       "  ('info', 1),\n",
       "  ('know', 1),\n",
       "  ('late', 1),\n",
       "  ('lerxst', 1),\n",
       "  ('line', 1),\n",
       "  ('look', 2),\n",
       "  ('mail', 1),\n",
       "  ('make', 1),\n",
       "  ('maryland_college', 1),\n",
       "  ('model', 1),\n",
       "  ('name', 1),\n",
       "  ('neighborhood', 1),\n",
       "  ('nntp_post', 1),\n",
       "  ('organization', 1),\n",
       "  ('park', 1),\n",
       "  ('production', 1),\n",
       "  ('rac_wam', 1),\n",
       "  ('really', 1),\n",
       "  ('rest', 1),\n",
       "  ('s', 1),\n",
       "  ('see', 1),\n",
       "  ('separate', 1),\n",
       "  ('small', 1),\n",
       "  ('spec', 1),\n",
       "  ('sport', 1),\n",
       "  ('tellme', 1),\n",
       "  ('thank', 1),\n",
       "  ('thing', 1),\n",
       "  ('umd', 1),\n",
       "  ('university', 1),\n",
       "  ('whatev', 1),\n",
       "  ('where', 1),\n",
       "  ('wonder', 1),\n",
       "  ('year', 1)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여태까지 해온 것이 LDA 모델 생성에 필요한 것들을 전부 한 것이다. 코퍼스와 딕셔너리를 생성한 것에 더해서, 우리는 몇 개의 토픽을 할당할 것인지에 대한 결정을 해주어야 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- alpha , eta 는 토픽들의 떨어진 정도(sparsity)에 영향을 끼치는 하이퍼 파라미터이다. 도큐먼트에 따르면, 디폴트값은 1.0/num_topics prior 이다.\n",
    "- chunksize 는 각각의 training chunk 에 사용될 문서의 갯수를 의미한다. 확실하지는 않지만, batch_size 와 유사한 의미를 갖는 것로 해석된다.\n",
    "\n",
    "    - IN ADDITION : Text chunking, also referred to as shallow parsing, is a task that follows Part-Of-Speech Tagging and that adds more structure to the sentence. The result is a grouping of the words in “chunks”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위의 모델을 통해 반환되는 것은 토픽의 수는 20개이고 각각의 키워드(단어들의 집합)와 키워드들 간의 조합이 특정한 토픽의 가중치를 정해주는데 기여하는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lda_model 객체에 print_topics 메소드를 operating 하면, 각각의 키워드들이 토픽에 기여하는 가중치(importance)를 알 수 있다.\n",
    "- 0부터 19까지 총 20개에 해당하는 토픽이 있는 것을 알 수 있고, 각각의 토픽에 위치해있는 키워드들과 이들 키워드들이 해당 토픽에서 가지는 중요도가 순서대로 나와있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pyLDAvis 만큼 jupyter notebook에서 LDA랄 잘 작동하면서 시각화하는 툴도 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Gensim 의 LDA 알고리즘보다 Mallet 버젼이 더 나은 퀄리티를 보여준다.\n",
    "- https://www.machinelearningplus.com/wp-content/uploads/2018/03/mallet-2.0.8.zip 깔고 해당 경로를 아래에 넣어주면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "mallet_path = '/home/hskimim/Documents/mallet-2.0.8/bin/mallet' # update this path\n",
    "ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)\n",
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "51에서 62로 Coherence Score 가 올라갔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA 에서 최적의 토픽 갯수 찾기\n",
    "- 많은 LDA 모델을 토픽 갯수(k)를 다르게 해서, 많이 시행해본 후, Coherance value 가 가장 높은 것을 선택한다.\n",
    "- 높은 Coherance Value 를 가지는 k를 선택하는 것은 유의미하고, 세부적인 토픽을 할당할 수 있게끔 한다.\n",
    "- 여러개의 토픽에 키워드가 많이 중첩되면, 이것은 k를 너무 높게 할당했다는 신호가 될 수 있다.\n",
    "- compute_coherence_values라는 메소드는 다수의 LDA 모델에 대한 Coherance value 를 알려준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8b28ea53c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 2  has Coherence Value of 0.4377\n",
      "Num Topics = 8  has Coherence Value of 0.5654\n",
      "Num Topics = 14  has Coherence Value of 0.6136\n",
      "Num Topics = 20  has Coherence Value of 0.6137\n",
      "Num Topics = 26  has Coherence Value of 0.6316\n",
      "Num Topics = 32  has Coherence Value of 0.6373\n",
      "Num Topics = 38  has Coherence Value of 0.6356\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimal_model= gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=32, id2word=id2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 해당 문장에서 지배적인 토픽을 찾기\n",
    "- 토픽 모델링의 주요 활용점은 해당 문서의 토픽이 무엇이냐에 관한 것이다.\n",
    "- 이를 알아내기 위해서는 해당 문서에서 가장 기여를 많이 한, 즉 중요도가 가장 높은 토픽의 넘버를 찾아야 한다.\n",
    "- format_topics_sentences() 메소드는 보여지는 테이블로 훌륭하게 정보를 병합해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=optimal_model, corpus=corpus, texts=data)\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']\n",
    "\n",
    "# Show\n",
    "df_dominant_topic.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각각의 토픽을 대표하는 문서찾기\n",
    "- 가끔 토픽 키워드(단어)는 단지 토픽들을 구성하는 것에 그치지 않는 경우가 있다.\n",
    "- 토픽을 이해하는 것을 넘어서, 토픽을 형성하는데 가장 많은 기여를 한 문서를 찾아낼 수도 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group top 5 sentences under each topic\n",
    "sent_topics_sorteddf_mallet = pd.DataFrame()\n",
    "\n",
    "sent_topics_outdf_grpd = df_topic_sents_keywords.groupby('Dominant_Topic')\n",
    "\n",
    "for i, grp in sent_topics_outdf_grpd:\n",
    "    sent_topics_sorteddf_mallet = pd.concat([sent_topics_sorteddf_mallet, \n",
    "                                             grp.sort_values(['Perc_Contribution'], ascending=[0]).head(1)], \n",
    "                                            axis=0)\n",
    "\n",
    "# Reset Index    \n",
    "sent_topics_sorteddf_mallet.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Format\n",
    "sent_topics_sorteddf_mallet.columns = ['Topic_Num', \"Topic_Perc_Contrib\", \"Keywords\", \"Text\"]\n",
    "\n",
    "# Show\n",
    "sent_topics_sorteddf_mallet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 문서를 넘어선 토픽 분배\n",
    "- 마지막으로 우리는 해당 정보에서 어떤 것들이 가장 많이 거론되었는지를 토픽의 크기(volume)과 분포(distribution)로 이해할 수 있게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of Documents for Each Topic\n",
    "topic_counts = df_topic_sents_keywords['Dominant_Topic'].value_counts()\n",
    "\n",
    "# Percentage of Documents for Each Topic\n",
    "topic_contribution = round(topic_counts/topic_counts.sum(), 4)\n",
    "\n",
    "# Topic Number and Keywords\n",
    "topic_num_keywords = df_topic_sents_keywords[['Dominant_Topic', 'Topic_Keywords']]\n",
    "\n",
    "# Concatenate Column wise\n",
    "df_dominant_topics = pd.concat([topic_num_keywords, topic_counts, topic_contribution], axis=1)\n",
    "\n",
    "# Change Column names\n",
    "df_dominant_topics.columns = ['Dominant_Topic', 'Topic_Keywords', 'Num_Documents', 'Perc_Documents']\n",
    "\n",
    "# Show\n",
    "df_dominant_topics.iloc[:10]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
